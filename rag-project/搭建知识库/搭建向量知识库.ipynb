{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 第三章 搭建向量知识库\n",
    "## 3.1 向量及向量知识库\n",
    "\n",
    "### 3.1.1 词向量与向量\n",
    "在机器学习和自然语言处理（NLP）中，词向量（word embedding）是一种以单词为单位将每个单词转化为实数向量的技术。这些实数向量可以被计算机更好地理解和处理。词向量背后的主要想理念是相似或相关的对象在向量空间中的距离应该很近。\n",
    "\n",
    "\n",
    "举个例子，我们可以使用词向量来表示文本数据。在词向量中，每个单词被转换为一个向量，这个向量捕获了这个单词的语义信息。例如，\"king\" 和 \"queen\" 这两个单词在向量空间中的位置将会非常接近，因为它们的含义相似。而 \"apple\" 和 \"orange\" 也会很接近，因为它们都是水果。而 \"king\" 和 \"apple\" 这两个单词在向量空间中的距离就会比较远，因为它们的含义不同。"
   ],
   "id": "88e1b4a4c486b70c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "词向量实际上是将单词转化为固定的静态的向量，虽然可以在一定程度上捕捉并表达文本中的语义信息，但忽略了单词在不同语境中的意思会受到影响这一现实。因此在RAG应用中使用的向量技术一般为通用文本向量(Universal text embedding)，该技术可以对一定范围内任意长度的文本进行向量化，与词向量不同的是向量化的单位不再是单词而是输入的文本，输出的向量会捕捉更多的语义信息。",
   "id": "e81dd50b3579db6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在RAG（Retrieval Augmented Generation，检索增强生成）方面向量的优势主要有两点：\n",
    "* 向量比文字更适合检索。当我们在数据库检索时，如果数据库存储的是文字，主要通过检索关键词（词法搜索）等方法找到相对匹配的数据，匹配的程度取决于数据库中的文档中是否含有查询句中的关键词；而向量中包含了原文本的语义信息，可以通过计算问题与数据库中数据的点积、余弦距离、欧几里得距离等指标，直接获取问题与数据在语义层面上的相似度；\n",
    "* 向量比其它媒介的综合信息能力更强，当传统数据库存储文字、声音、图像、视频等多种媒介时，很难去将上述多种媒介构建起关联与跨模态的查询方法；但是向量却可以通过多种向量模型将多种数据映射成统一的向量形式。"
   ],
   "id": "34d32462abbde890"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在搭建 RAG 系统时，我们往往可以通过使用向量模型来构建向量，我们可以选择：\n",
    "* 使用各个公司的 Embedding API；\n",
    "* 在本地使用向量模型将数据构建为向量。"
   ],
   "id": "21104f4147b5ca5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.1.2 向量数据库\n",
    "\n",
    "向量数据库是用于高效计算和管理大量向量数据的解决方案。向量数据库是一种专门用于存储和检索向量数据（embedding）的数据库系统。它与传统的基于关系模型的数据库不同，它主要关注的是向量数据的特性和相似性。\n",
    "\n",
    "在向量数据库中，数据被表示为向量形式，每个向量代表一个数据项。这些向量可以是数字、文本、图像或其他类型的数据。向量数据库使用高效的索引和查询算法来加速向量数据的存储和检索过程。\n",
    "\n",
    "向量数据库中的数据以向量作为基本单位，对向量进行存储、处理及检索。向量数据库通过计算与目标向量的余弦距离、点积等获取与目标向量的相似度。当处理大量甚至海量的向量数据时，向量数据库索引和查询算法的效率明显高于传统数据库。\n",
    "\n",
    "* [Chroma](https://www.trychroma.com/)：是一个轻量级向量数据库，拥有丰富的功能和简单的 API，具有简单、易用、轻量的优点，但功能相对简单且不支持GPU加速，适合初学者使用。\n",
    "* [Weaviate](https://weaviate.io/)：是一个开源向量数据库。除了支持相似度搜索和最大边际相关性（MMR，Maximal Marginal Relevance）搜索外还可以支持结合多种搜索算法（基于词法搜索、向量搜索）的混合搜索，从而提高搜索结果的相关性和准确性。\n",
    "* [Qdrant](https://qdrant.tech/)：Qdrant使用 Rust 语言开发，有极高的检索效率和RPS（Requests Per Second），支持本地运行、部署在本地服务器及Qdrant云三种部署模式。且可以通过为页面内容和元数据制定不同的键来复用数据。"
   ],
   "id": "362c6a5d5fae261a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2 使用Embedding API\n",
    "注：为了方便embedding api调用，应将密钥填入llm_universe下的.env文件，代码将自动读取并加载环境变量。"
   ],
   "id": "af79101a67e592a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T04:42:21.023431Z",
     "start_time": "2025-06-16T04:42:20.364948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from zhipuai import ZhipuAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "# 读取本地/项目的环境变量。\n",
    "# find_dotenv()寻找并定位.env文件的路径\n",
    "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中\n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "def zhipu_embedding(text: str):\n",
    "\n",
    "    api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "    client = ZhipuAI(api_key=api_key)\n",
    "    response = client.embeddings.create(\n",
    "        model=\"embedding-3\",\n",
    "        input=text,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "text = '要生成 embedding 的输入文本，字符串形式。'\n",
    "response = zhipu_embedding(text=text)"
   ],
   "id": "a8af8423e5a4b7d2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "response为`zhipuai.types.embeddings.EmbeddingsResponded`类型，我们可以调用`object`、`data`、`model`、`usage`来查看response的embedding类型、embedding、embedding model及使用情况。",
   "id": "9a22d841189ee3c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T05:22:51.995304Z",
     "start_time": "2025-06-16T05:22:51.992479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'response类型为：{type(response)}')\n",
    "print(f'embedding类型为：{response.object}')\n",
    "print(f'生成embedding的model为：{response.model}')\n",
    "print(f'生成的embedding长度为：{len(response.data[0].embedding)}')\n",
    "print(f'embedding（前10）为: {response.data[0].embedding[:10]}')"
   ],
   "id": "d1f69528ab5308d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response类型为：<class 'zhipuai.types.embeddings.EmbeddingsResponded'>\n",
      "embedding类型为：list\n",
      "生成embedding的model为：embedding-3\n",
      "生成的embedding长度为：2048\n",
      "embedding（前10）为: [-0.0042974288, 0.040918995, -0.0036798029, 0.034753118, -0.047749206, -0.015196704, -0.023666998, -0.002935019, 0.0015090306, -0.011958062]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.3 数据处理\n",
    "\n",
    "为构建我们的本地知识库，我们需要对以多种类型存储的本地文档进行处理，读取本地文档并通过前文描述的 Embedding 方法将本地文档的内容转化为词向量来构建向量数据库。在本节中，我们以一些实际示例入手，来讲解如何对本地文档进行处理。\n",
    "### 3.3.1 源文档选取\n",
    "我们选用 Datawhale 一些经典开源课程作为示例，具体包括：\n",
    "* [《机器学习公式详解》PDF版本](https://github.com/datawhalechina/pumpkin-book/releases)\n",
    "* [《面向开发者的LLM入门教程、第一部分Prompt Engineering》md版本](https://github.com/datawhalechina/llm-cookbook)\n",
    "我们将知识库源数据放置在../../data_base/knowledge_db 目录下。\n",
    "### 3.3.2 数据读取\n",
    "对于PDF 文档，我们可以使用 LangChain 的 PyMuPDFLoader 来读取知识库的 PDF 文件。PyMuPDFLoader 是 PDF 解析器中速度最快的一种，结果会包含 PDF 及其页面的详细元数据，并且每页返回一个文档。"
   ],
   "id": "c4b0dd3815fbe6b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T05:55:57.217673Z",
     "start_time": "2025-06-16T05:55:56.934115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "#创建一个PyMuPDFLoader Class 实例，输入为待加载的pdf文档路径\n",
    "loader = PyMuPDFLoader(\"../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf\")\n",
    "\n",
    "# 调用 PyMuPDFLoader Class 的函数 load 对 pdf 文件进行加载\n",
    "pdf_pages = loader.load()"
   ],
   "id": "7984d9f2d68e16e4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "文档加载后储存在 `pages` 变量中:\n",
    "- `page` 的变量类型为 `List`\n",
    "- 打印 `pages` 的长度可以看到 pdf 一共包含多少页"
   ],
   "id": "a68377c01979e67c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:02:33.606661Z",
     "start_time": "2025-06-16T06:02:33.603215Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"载入后的变量类型为：{type(pdf_pages)}\",f\"该pdf一共包含{len(pdf_pages)}页\")",
   "id": "98872669ff4dc648",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入后的变量类型为：<class 'list'> 该pdf一共包含196页\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`page` 中的每一元素为一个文档，变量类型为 `langchain_core.documents.base.Document`, 文档变量类型包含两个属性\n",
    "- `page_content` 包含该文档的内容。\n",
    "- `meta_data` 为文档相关的描述性数据。"
   ],
   "id": "3b3351daa0b78665"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:27:48.723897Z",
     "start_time": "2025-06-16T06:27:48.720619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pdf_page = pdf_pages[1]\n",
    "print(f\"每一个元素的类型：{type(pdf_page)}.\",\n",
    "      f\"该文档的描述性数据：{pdf_page.metadata}\",\n",
    "      f\"查看该文档的内容：\\n{pdf_page.page_content}\",\n",
    "      sep=\"\\n----\\n\"\n",
    "      )"
   ],
   "id": "46ca6bd79994bd69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "----\n",
      "该文档的描述性数据：{'source': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'file_path': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'page': 1, 'total_pages': 196, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'xdvipdfmx (20200315)', 'creationDate': \"D:20230303170709-00'00'\", 'modDate': '', 'trapped': ''}\n",
      "----\n",
      "查看该文档的内容：\n",
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以...... 本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；\n",
      "• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；\n",
      "• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；\n",
      "• 若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们GitHub 的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）\n",
      "最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、\n",
      "spareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "对于 markdown 文档我们可以以几乎完全一致的方式读入。",
   "id": "de80c18870b6e9fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:16:40.211756Z",
     "start_time": "2025-06-16T06:16:36.716041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = UnstructuredMarkdownLoader(\"../data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md\")\n",
    "md_pages = loader.load()"
   ],
   "id": "b64b8c7479e47cb1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "读取的对象和 PDF 文档读取出来是完全一致的：",
   "id": "3504e89f2e2486c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:23:16.533363Z",
     "start_time": "2025-06-16T06:23:16.527590Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"载入后的变量类型为：{type(md_pages)},\", f\"该markdown一共包含{len(md_pages)}页\")",
   "id": "89ad33a32fe52d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入后的变量类型为：<class 'list'>, 该markdown一共包含1页\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:24:34.992895Z",
     "start_time": "2025-06-16T06:24:34.990130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "md_page = md_pages[0]\n",
    "print(f\"每一个元素的类型：{type(md_page)}.\",\n",
    "    f\"该文档的描述性数据：{md_page.metadata}\",\n",
    "    f\"查看该文档的内容:\\n{md_page.page_content[0:][:400]}\",\n",
    "    sep=\"\\n------\\n\")"
   ],
   "id": "b50ecfe0114c412e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md'}\n",
      "------\n",
      "查看该文档的内容:\n",
      "第一章 简介\n",
      "\n",
      "欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model， 大语言模型）技术在产品中的应用方面做出了很大贡献。她还参与编写了教授人们使用 Prompt 的 OpenAI cookbook。我们希望通过本模块的学习，与大家分享使用提示词开发 LLM 应用的最佳实践和技巧。\n",
      "\n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.3.3 数据清洗\n",
    "我们期望知识库的数据尽量是有序的、优质的、精简的，因此我们要删除低质量的、甚至影响理解的文本数据。\n",
    "可以看到上文中读取的pdf文件不仅将一句话按照原文的分行添加了换行符`\\n`，也在原本两个符号中间插入了`\\n`，我们可以使用正则表达式匹配并删除掉`\\n`。"
   ],
   "id": "f373d95fd24cfc06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:50:55.174335Z",
     "start_time": "2025-06-16T06:50:55.165510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "pattern = re.compile(r'[^\\u4e00-\\u9fff](\\n)[^\\u4e00-\\u9fff]', re.DOTALL)\n",
    "pdf_page.page_content = re.sub(pattern, lambda match: match.group(0).replace('\\n', ''), pdf_page.page_content)\n",
    "print(pdf_page.page_content)"
   ],
   "id": "936a9520145bd95d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以...... 本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；• 若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们GitHub 的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）\n",
      "最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、spareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "进一步分析数据，我们发现数据中还有不少的`•`和空格，我们使用replace方法去掉即可。",
   "id": "faf372d1e40eefd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:51:54.668997Z",
     "start_time": "2025-06-16T06:51:54.666488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pdf_page.page_content = pdf_page.page_content.replace('•', '')\n",
    "pdf_page.page_content = pdf_page.page_content.replace(' ', '')\n",
    "print(pdf_page.page_content)"
   ],
   "id": "e49c4d7d8605442",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解,所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以......本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；对于初学机器学习的小白，西瓜书第1章和第2章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；每个公式的解析和推导我们都力(zhi)争(neng)以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们GitHub的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24小时以内给您回复，超过24小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1版）\n",
      "最新版PDF获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、spareribs、sunchaothu、StevenLzq在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "上文中读取的md文件每一段中间隔了一个换行符，我们同样可以使用replace方法去除。",
   "id": "1f88d7196b89f40b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:53:35.056365Z",
     "start_time": "2025-06-16T06:53:35.052974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "md_page.page_content = md_page.page_content.replace('\\n\\n', '\\n')\n",
    "print(md_page.page_content)"
   ],
   "id": "9e6992339f34d41d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一章 简介\n",
      "欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model， 大语言模型）技术在产品中的应用方面做出了很大贡献。她还参与编写了教授人们使用 Prompt 的 OpenAI cookbook。我们希望通过本模块的学习，与大家分享使用提示词开发 LLM 应用的最佳实践和技巧。\n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 DeepLearning.AI 的姊妹公司 AI Fund 的团队一直在与许多初创公司合作，将这些技术应用于诸多应用程序上。很兴奋能看到 LLM API 能够让开发人员非常快速地构建应用程序。\n",
      "在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。\n",
      "随着 LLM 的发展，其大致可以分为两种类型，后续称为基础 LLM 和指令微调（Instruction Tuned）LLM。基础LLM是基于文本训练数据，训练出预测下一个单词能力的模型。其通常通过在互联网和其他来源的大量数据上训练，来确定紧接着出现的最可能的词。例如，如果你以“从前，有一只独角兽”作为 Prompt ，基础 LLM 可能会继续预测“她与独角兽朋友共同生活在一片神奇森林中”。但是，如果你以“法国的首都是什么”为 Prompt ，则基础 LLM 可能会根据互联网上的文章，将回答预测为“法国最大的城市是什么？法国的人口是多少？”，因为互联网上的文章很可能是有关法国国家的问答题目列表。\n",
      "与基础语言模型不同，指令微调 LLM 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行预训练，掌握语言的基本规律。在此基础上进行进一步的训练与微调（finetune），输入是指令，输出是对这些指令的正确回复。有时还会采用RLHF（reinforcement learning from human feedback，人类反馈强化学习）技术，根据人类对模型输出的反馈进一步增强模型遵循指令的能力。通过这种受控的训练过程。指令微调 LLM 可以生成对指令高度敏感、更安全可靠的输出，较少无关和损害性内容。因此。许多实际应用已经转向使用这类大语言模型。\n",
      "因此，本课程将重点介绍针对指令微调 LLM 的最佳实践，我们也建议您将其用于大多数使用场景。当您使用指令微调 LLM 时，您可以类比为向另一个人提供指令（假设他很聪明但不知道您任务的具体细节）。因此，当 LLM 无法正常工作时，有时是因为指令不够清晰。例如，如果您想问“请为我写一些关于阿兰·图灵( Alan Turing )的东西”，在此基础上清楚表明您希望文本专注于他的科学工作、个人生活、历史角色或其他方面可能会更有帮助。另外您还可以指定回答的语调， 来更加满足您的需求，可选项包括专业记者写作，或者向朋友写的随笔等。\n",
      "如果你将 LLM 视为一名新毕业的大学生，要求他完成这个任务，你甚至可以提前指定他们应该阅读哪些文本片段来写关于阿兰·图灵的文本，这样能够帮助这位新毕业的大学生更好地完成这项任务。本书的下一章将详细阐释提示词设计的两个关键原则：清晰明确和给予充足思考时间。\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.3.4 文档分割\n",
    "\n",
    "由于单个文档的长度往往会超过模型支持的上下文，导致检索得到的知识太长超出模型的处理能力，因此，在构建向量知识库的过程中，我们往往需要对文档进行分割，将单个文档按长度或者按固定的规则分割成若干个 chunk，然后将每个 chunk 转化为词向量，存储到向量数据库中。\n",
    "\n",
    "在检索时，我们会以 chunk 作为检索的元单位，也就是每一次检索到 k 个 chunk 作为模型可以参考来回答用户问题的知识，这个 k 是我们可以自由设定的。\n",
    "\n",
    "Langchain 中文本分割器都根据 `chunk_size` (块大小)和 `chunk_overlap` (块与块之间的重叠大小)进行分割。\n",
    "\n",
    "* chunk_size 指每个块包含的字符或 Token （如单词、句子等）的数量\n",
    "\n",
    "* chunk_overlap 指两个块之间共享的字符数量，用于保持上下文的连贯性，避免分割丢失上下文信息"
   ],
   "id": "a505341461f6e154"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Langchain 提供多种文档分割方式，区别在怎么确定块与块之间的边界、块由哪些字符/token组成、以及如何测量块大小\n",
    "\n",
    "- RecursiveCharacterTextSplitter(): 按字符串分割文本，递归地尝试按不同的分隔符进行分割文本。\n",
    "- CharacterTextSplitter(): 按字符来分割文本。\n",
    "- MarkdownHeaderTextSplitter(): 基于指定的标题来分割markdown 文件。\n",
    "- TokenTextSplitter(): 按token来分割文本。\n",
    "- SentenceTransformersTokenTextSplitter(): 按token来分割文本\n",
    "- Language(): 用于 CPP、Python、Ruby、Markdown 等。\n",
    "- NLTKTextSplitter(): 使用 NLTK（自然语言工具包）按句子分割文本。\n",
    "- SpacyTextSplitter(): 使用 Spacy按句子的切割文本。"
   ],
   "id": "94295325937f3455"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:06:07.163294Z",
     "start_time": "2025-06-16T07:06:07.147085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "* RecursiveCharacterTextSplitter 递归字符文本分割\n",
    "RecursiveCharacterTextSplitter 将按不同的字符递归地分割(按照这个优先级[\"\\n\\n\", \"\\n\", \" \", \"\"])，\n",
    "    这样就能尽量把所有和语义相关的内容尽可能长时间地保留在同一位置\n",
    "RecursiveCharacterTextSplitter需要关注的是4个参数：\n",
    "\n",
    "* separators - 分隔符字符串数组\n",
    "* chunk_size - 每个文档的字符数量限制\n",
    "* chunk_overlap - 两份文档重叠区域的长度\n",
    "* length_function - 长度计算函数\n",
    "'''\n",
    "#导入文本分割器\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 知识库中单段文本长度\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "# 知识库中相邻文本重合长度\n",
    "OVERLAP_SIZE = 50\n",
    "\n",
    "# 使用递归字符文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=OVERLAP_SIZE\n",
    ")\n",
    "text_splitter.split_text(pdf_page.page_content[0:1000])"
   ],
   "id": "f75f19a3ac81edfb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['前言\\n“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\\n者通过西瓜书对机器学习有所了解,所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\\n导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\\n具体的推导细节。”\\n读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\\n老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\\n中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以......本南瓜书只能算是我\\n等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\\n下学生”。\\n使用说明\\n南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\\n为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；对于初学机器学习的小白，西瓜书第1章和第2章的公式强烈不建议深究，简单过一下即可，等你学得',\n",
       " '有点飘的时候再回来啃都来得及；每个公式的解析和推导我们都力(zhi)争(neng)以本科数学基础的视角进行讲解，所以超纲的数学知识\\n我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们GitHub的\\nIssues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\\n提交你希望补充的公式编号或者勘误信息，我们通常会在24小时以内给您回复，超过24小时未回复的\\n话可以微信联系我们（微信号：at-Sm1les）；\\n配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\\n在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1版）\\n最新版PDF获取地址：https://github.com/datawhalechina/pumpkin-book/releases\\n编委会',\n",
       " '编委会\\n主编：Sm1les、archwalker']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:07:00.487831Z",
     "start_time": "2025-06-16T07:07:00.458506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "split_docs = text_splitter.split_documents(pdf_pages)\n",
    "print(f\"切分后的文件数量：{len(split_docs)}\")"
   ],
   "id": "8f8d1f1518359f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的文件数量：711\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:07:35.667063Z",
     "start_time": "2025-06-16T07:07:35.664370Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"切分后的字符数（可以用来大致评估 token 数）：{sum([len(doc.page_content) for doc in split_docs])}\")",
   "id": "340d12f38878b5b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的字符数（可以用来大致评估 token 数）：305816\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.4 搭建并使用向量数据库\n",
    "### 3.4.1 前序配置\n",
    "本节重点为搭建并使用向量数据库，因此读取数据后我们省去数据处理的环节直入主题，数据清洗等步骤可以参考第三节"
   ],
   "id": "7edccaae896ecd45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:11:07.598720Z",
     "start_time": "2025-06-16T07:11:07.593162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 读取本地/项目的环境变量。\n",
    "# find_dotenv()寻找并定位.env文件的路径\n",
    "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中\n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 获取folder_path下所有文件路径，储存在file_paths里\n",
    "file_paths = []\n",
    "folder_path = '../data_base/knowledge_db'\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "print(file_paths[:10])"
   ],
   "id": "c7966bf72eb669e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data_base/knowledge_db/prompt_engineering/6. 文本转换 Transforming.md', '../data_base/knowledge_db/prompt_engineering/4. 文本概括 Summarizing.md', '../data_base/knowledge_db/prompt_engineering/5. 推断 Inferring.md', '../data_base/knowledge_db/prompt_engineering/8. 聊天机器人 Chatbot.md', '../data_base/knowledge_db/prompt_engineering/9. 总结 Summary.md', '../data_base/knowledge_db/prompt_engineering/2. 提示原则 Guidelines.md', '../data_base/knowledge_db/prompt_engineering/3. 迭代优化 Iterative.md', '../data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md', '../data_base/knowledge_db/prompt_engineering/7. 文本扩展 Expanding.md', '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf']\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:16:49.339060Z",
     "start_time": "2025-06-16T07:16:48.734387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "#遍历文件路径并把实例化的loader存放在loaders里面\n",
    "loaders = []\n",
    "for file_path in file_paths:\n",
    "    file_type = file_path.split('.')[-1]\n",
    "    if file_type == 'pdf':\n",
    "        loaders.append(PyMuPDFLoader(file_path))\n",
    "    elif file_type == 'md':\n",
    "        loaders.append(UnstructuredMarkdownLoader(file_path))\n",
    "\n",
    "#下载文件并存储到text里\n",
    "texts = []\n",
    "for loader in loaders:\n",
    "    texts.extend(loader.load())"
   ],
   "id": "75f940f0b449f374",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "载入后的变量类型为`langchain_core.documents.base.Document`, 文档变量类型同样包含两个属性\n",
    "- `page_content` 包含该文档的内容。\n",
    "- `meta_data` 为文档相关的描述性数据。"
   ],
   "id": "5af90826a3c4b891"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:19:41.478029Z",
     "start_time": "2025-06-16T07:19:41.473927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = texts[2]\n",
    "print(f\"每一个元素的类型：{type(text)}.\",\n",
    "    f\"该文档的描述性数据：{text.metadata}\",\n",
    "    f\"查看该文档的内容:\\n{text.page_content[0:]}\",\n",
    "    sep=\"\\n------\\n\")"
   ],
   "id": "c5d65fcfae258042",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../data_base/knowledge_db/prompt_engineering/5. 推断 Inferring.md'}\n",
      "------\n",
      "查看该文档的内容:\n",
      "第五章 推断\n",
      "\n",
      "在这一章中，我们将通过一个故事，引领你了解如何从产品评价和新闻文章中推导出情感和主题。\n",
      "\n",
      "让我们先想象一下，你是一名初创公司的数据分析师，你的任务是从各种产品评论和新闻文章中提取出关键的情感和主题。这些任务包括了标签提取、实体提取、以及理解文本的情感等等。在传统的机器学习流程中，你需要收集标签化的数据集、训练模型、确定如何在云端部署模型并进行推断。尽管这种方式可能会产生不错的效果，但完成这一全流程需要耗费大量的时间和精力。而且，每一个任务，比如情感分析、实体提取等等，都需要训练和部署单独的模型。\n",
      "\n",
      "然而，就在你准备投入繁重工作的时候，你发现了大型语言模型（LLM）。LLM 的一个明显优点是，对于许多这样的任务，你只需要编写一个 Prompt，就可以开始生成结果，大大减轻了你的工作负担。这个发现像是找到了一把神奇的钥匙，让应用程序开发的速度加快了许多。最令你兴奋的是，你可以仅仅使用一个模型和一个 API 来执行许多不同的任务，无需再纠结如何训练和部署许多不同的模型。\n",
      "\n",
      "让我们开始这一章的学习，一起探索如何利用 LLM 加快我们的工作进程，提高我们的工作效率。\n",
      "\n",
      "一、情感推断\n",
      "\n",
      "1.1 情感倾向分析\n",
      "\n",
      "让我们以一则电商平台上的台灯评论为例，通过此例，我们将学习如何对评论进行情感二分类（正面/负面）。\n",
      "\n",
      "python lamp_review = \"\"\" 我需要一盏漂亮的卧室灯，这款灯具有额外的储物功能，价格也不算太高。\\ 我很快就收到了它。在运输过程中，我们的灯绳断了，但是公司很乐意寄送了一个新的。\\ 几天后就收到了。这款灯很容易组装。我发现少了一个零件，于是联系了他们的客服，他们很快就给我寄来了缺失的零件！\\ 在我看来，Lumina 是一家非常关心顾客和产品的优秀公司！ \"\"\"\n",
      "\n",
      "接下来，我们将尝试编写一个 Prompt ，用以分类这条商品评论的情感。如果我们想让系统解析这条评论的情感倾向，只需编写“以下商品评论的情感倾向是什么？”这样的 Prompt ，再加上一些标准的分隔符和评论文本等。\n",
      "\n",
      "然后，我们将这个程序运行一遍。结果表明，这条商品评论的情感倾向是正面的，这似乎非常准确。尽管这款台灯并非完美无缺，但是这位顾客对它似乎相当满意。这个公司看起来非常重视客户体验和产品质量，因此，认定评论的情感倾向为正面似乎是正确的判断。\n",
      "\n",
      "```python from tool import get_completion\n",
      "\n",
      "prompt = f\"\"\" 以下用三个反引号分隔的产品评论的情感是什么？\n",
      "\n",
      "评论文本: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "情感是积极的。\n",
      "\n",
      "如果你想要给出更简洁的答案，以便更容易进行后期处理，可以在上述 Prompt 基础上添加另一个指令：用一个单词回答：「正面」或「负面」。这样就只会打印出 “正面” 这个单词，这使得输出更加统一，方便后续处理。\n",
      "\n",
      "```python prompt = f\"\"\" 以下用三个反引号分隔的产品评论的情感是什么？\n",
      "\n",
      "用一个单词回答：「正面」或「负面」。\n",
      "\n",
      "评论文本: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "正面\n",
      "\n",
      "1.2 识别情感类型\n",
      "\n",
      "接下来，我们将继续使用之前的台灯评论，但这次我们会试用一个新的 Prompt 。我们希望模型能够识别出评论作者所表达的情感，并且将这些情感整理为一个不超过五项的列表。\n",
      "\n",
      "```python\n",
      "\n",
      "中文\n",
      "\n",
      "prompt = f\"\"\" 识别以下评论的作者表达的情感。包含不超过五个项目。将答案格式化为以逗号分隔的单词列表。\n",
      "\n",
      "评论文本: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "满意,感激,赞赏,信任,满足\n",
      "\n",
      "大型语言模型非常擅长从一段文本中提取特定的东西。在上面的例子中，评论所表达的情感有助于了解客户如何看待特定的产品。\n",
      "\n",
      "1.3 识别愤怒\n",
      "\n",
      "对于许多企业来说，洞察到顾客的愤怒情绪是至关重要的。这就引出了一个分类问题：下述的评论作者是否流露出了愤怒？因为如果有人真的情绪激动，那可能就意味着需要给予额外的关注，因为每一个愤怒的顾客都是一个改进服务的机会，也是一个提升公司口碑的机会。这时，客户支持或者客服团队就应该介入，与客户接触，了解具体情况，然后解决他们的问题。\n",
      "\n",
      "```python\n",
      "\n",
      "中文\n",
      "\n",
      "prompt = f\"\"\" 以下评论的作者是否表达了愤怒？评论用三个反引号分隔。给出是或否的答案。\n",
      "\n",
      "评论文本: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "上面这个例子中，客户并没有生气。注意，如果使用常规的监督学习，如果想要建立所有这些分类器，不可能在几分钟内就做到这一点。我们鼓励大家尝试更改一些这样的 Prompt ，也许询问客户是否表达了喜悦，或者询问是否有任何遗漏的部分，并看看是否可以让 Prompt 对这个灯具评论做出不同的推论。\n",
      "\n",
      "二、信息提取\n",
      "\n",
      "2.1 商品信息提取\n",
      "\n",
      "信息提取是自然语言处理（NLP）的重要组成部分，它帮助我们从文本中抽取特定的、我们关心的信息。我们将深入挖掘客户评论中的丰富信息。在接下来的示例中，我们将要求模型识别两个关键元素：购买的商品和商品的制造商。\n",
      "\n",
      "想象一下，如果你正在尝试分析一个在线电商网站上的众多评论，了解评论中提到的商品是什么、由谁制造，以及相关的积极或消极情绪，将极大地帮助你追踪特定商品或制造商在用户心中的情感趋势。\n",
      "\n",
      "在接下来的示例中，我们会要求模型将回应以一个 JSON 对象的形式呈现，其中的 key 就是商品和品牌。\n",
      "\n",
      "```python\n",
      "\n",
      "中文\n",
      "\n",
      "prompt = f\"\"\" 从评论文本中识别以下项目： - 评论者购买的物品 - 制造该物品的公司\n",
      "\n",
      "评论文本用三个反引号分隔。将你的响应格式化为以 “物品” 和 “品牌” 为键的 JSON 对象。 如果信息不存在，请使用 “未知” 作为值。 让你的回应尽可能简短。\n",
      "\n",
      "评论文本: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "{\n",
      "  \"物品\": \"卧室灯\",\n",
      "  \"品牌\": \"Lumina\"\n",
      "}\n",
      "\n",
      "如上所示，它会说这个物品是一个卧室灯，品牌是 Luminar，你可以轻松地将其加载到 Python 字典中，然后对此输出进行其他处理。\n",
      "\n",
      "2.2 综合情感推断和信息提取\n",
      "\n",
      "在上面小节中，我们采用了三至四个 Prompt 来提取评论中的“情绪倾向”、“是否生气”、“物品类型”和“品牌”等信息。然而，事实上，我们可以设计一个单一的 Prompt ，来同时提取所有这些信息。\n",
      "\n",
      "```python\n",
      "\n",
      "中文\n",
      "\n",
      "prompt = f\"\"\" 从评论文本中识别以下项目： - 情绪（正面或负面） - 审稿人是否表达了愤怒？（是或否） - 评论者购买的物品 - 制造该物品的公司\n",
      "\n",
      "评论用三个反引号分隔。将你的响应格式化为 JSON 对象，以 “情感倾向”、“是否生气”、“物品类型” 和 “品牌” 作为键。 如果信息不存在，请使用 “未知” 作为值。 让你的回应尽可能简短。 将 “是否生气” 值格式化为布尔值。\n",
      "\n",
      "评论文本: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "{\n",
      "  \"情感倾向\": \"正面\",\n",
      "  \"是否生气\": false,\n",
      "  \"物品类型\": \"卧室灯\",\n",
      "  \"品牌\": \"Lumina\"\n",
      "}\n",
      "\n",
      "这个例子中，我们指导 LLM 将“是否生气”的情况格式化为布尔值，并输出 JSON 格式。你可以尝试对格式化模式进行各种变化，或者使用完全不同的评论来试验，看看 LLM 是否仍然可以准确地提取这些内容。\n",
      "\n",
      "三、主题推断\n",
      "\n",
      "大型语言模型的另一个很酷的应用是推断主题。假设我们有一段长文本，我们如何判断这段文本的主旨是什么？它涉及了哪些主题？让我们通过以下一段虚构的报纸报道来具体了解一下。\n",
      "\n",
      "```python\n",
      "\n",
      "中文\n",
      "\n",
      "story = \"\"\" 在政府最近进行的一项调查中，要求公共部门的员工对他们所在部门的满意度进行评分。 调查结果显示，NASA 是最受欢迎的部门，满意度为 95％。\n",
      "\n",
      "一位 NASA 员工 John Smith 对这一发现发表了评论，他表示： “我对 NASA 排名第一并不感到惊讶。这是一个与了不起的人们和令人难以置信的机会共事的好地方。我为成为这样一个创新组织的一员感到自豪。”\n",
      "\n",
      "NASA 的管理团队也对这一结果表示欢迎，主管 Tom Johnson 表示： “我们很高兴听到我们的员工对 NASA 的工作感到满意。 我们拥有一支才华横溢、忠诚敬业的团队，他们为实现我们的目标不懈努力，看到他们的辛勤工作得到回报是太棒了。”\n",
      "\n",
      "调查还显示，社会保障管理局的满意度最低，只有 45％的员工表示他们对工作满意。 政府承诺解决调查中员工提出的问题，并努力提高所有部门的工作满意度。 \"\"\" ```\n",
      "\n",
      "3.1 推断讨论主题\n",
      "\n",
      "以上是一篇关于政府员工对其工作单位感受的虚构报纸文章。我们可以要求大语言模型确定其中讨论的五个主题，并用一两个词语概括每个主题。输出结果将会以逗号分隔的Python列表形式呈现。\n",
      "\n",
      "```python\n",
      "\n",
      "中文\n",
      "\n",
      "prompt = f\"\"\" 确定以下给定文本中讨论的五个主题。\n",
      "\n",
      "每个主题用1-2个词概括。\n",
      "\n",
      "请输出一个可解析的Python列表，每个元素是一个字符串，展示了一个主题。\n",
      "\n",
      "给定文本: {story} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "['NASA', '满意度', '评论', '管理团队', '社会保障管理局']\n",
      "\n",
      "3.2 为特定主题制作新闻提醒\n",
      "\n",
      "假设我们有一个新闻网站或类似的平台，这是我们感兴趣的主题：美国航空航天局、当地政府、工程、员工满意度、联邦政府等。我们想要分析一篇新闻文章，理解其包含了哪些主题。可以使用这样的 Prompt：确定以下主题列表中的每个项目是否是以下文本中的主题。以 0 或 1 的形式给出答案列表。\n",
      "\n",
      "```python\n",
      "\n",
      "中文\n",
      "\n",
      "prompt = f\"\"\" 判断主题列表中的每一项是否是给定文本中的一个话题，\n",
      "\n",
      "以列表的形式给出答案，每个元素是一个Json对象，键为对应主题，值为对应的 0 或 1。\n",
      "\n",
      "主题列表：美国航空航天局、当地政府、工程、员工满意度、联邦政府\n",
      "\n",
      "给定文本: {story} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "[\n",
      "  {\"美国航空航天局\": 1},\n",
      "  {\"当地政府\": 1},\n",
      "  {\"工程\": 0},\n",
      "  {\"员工满意度\": 1},\n",
      "  {\"联邦政府\": 1}\n",
      "]\n",
      "\n",
      "从输出结果来看，这个 story 与关于“美国航空航天局”、“员工满意度”、“联邦政府”、“当地政府”有关，而与“工程”无关。这种能力在机器学习领域被称为零样本（Zero-Shot）学习。这是因为我们并没有提供任何带标签的训练数据，仅凭 Prompt ，它便能判定哪些主题在新闻文章中被包含。\n",
      "\n",
      "如果我们希望制定一个新闻提醒，我们同样可以运用这种处理新闻的流程。假设我对“美国航空航天局”的工作深感兴趣，那么你就可以构建一个如此的系统：每当出现与'美国宇航局'相关的新闻，系统就会输出提醒。\n",
      "\n",
      "python result_lst = eval(response) topic_dict = {list(i.keys())[0] : list(i.values())[0] for i in result_lst} print(topic_dict) if topic_dict['美国航空航天局'] == 1: print(\"提醒: 关于美国航空航天局的新消息\")\n",
      "\n",
      "{'美国航空航天局': 1, '当地政府': 1, '工程': 0, '员工满意度': 1, '联邦政府': 1}\n",
      "提醒: 关于美国航空航天局的新消息\n",
      "\n",
      "这就是我们关于推断的全面介绍。在短短几分钟内，我们已经能够建立多个用于文本推理的系统，这是以前需要机器学习专家数天甚至数周时间才能完成的任务。这一变化无疑是令人兴奋的，因为无论你是经验丰富的机器学习开发者，还是刚入门的新手，都能利用输入 Prompt 快速开始复杂的自然语言处理任务。\n",
      "\n",
      "英文版\n",
      "\n",
      "1.1 情感倾向分析\n",
      "\n",
      "python lamp_review = \"\"\" Needed a nice lamp for my bedroom, and this one had \\ additional storage and not too high of a price point. \\ Got it fast. The string to our lamp broke during the \\ transit and the company happily sent over a new one. \\ Came within a few days as well. It was easy to put \\ together. I had a missing part, so I contacted their \\ support and they very quickly got me the missing piece! \\ Lumina seems to me to be a great company that cares \\ about their customers and products!! \"\"\"\n",
      "\n",
      "```python prompt = f\"\"\" What is the sentiment of the following product review, which is delimited with triple backticks?\n",
      "\n",
      "Review text: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "The sentiment of the product review is positive.\n",
      "\n",
      "```python prompt = f\"\"\" What is the sentiment of the following product review, which is delimited with triple backticks?\n",
      "\n",
      "Give your answer as a single word, either \"positive\" \\ or \"negative\".\n",
      "\n",
      "Review text: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "positive\n",
      "\n",
      "1.2识别情感类型\n",
      "\n",
      "```python prompt = f\"\"\" Identify a list of emotions that the writer of the \\ following review is expressing. Include no more than \\ five items in the list. Format your answer as a list of \\ lower-case words separated by commas.\n",
      "\n",
      "Review text: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "satisfied, pleased, grateful, impressed, happy\n",
      "\n",
      "1.3 识别愤怒\n",
      "\n",
      "```python prompt = f\"\"\" Is the writer of the following review expressing anger?\\ The review is delimited with triple backticks. \\ Give your answer as either yes or no.\n",
      "\n",
      "Review text: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "No\n",
      "\n",
      "2.1 商品信息提取\n",
      "\n",
      "```python prompt = f\"\"\" Identify the following items from the review text: - Item purchased by reviewer - Company that made the item\n",
      "\n",
      "The review is delimited with triple backticks. \\ Format your response as a JSON object with \\ \"Item\" and \"Brand\" as the keys. If the information isn't present, use \"unknown\" \\ as the value. Make your response as short as possible.\n",
      "\n",
      "Review text: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "{\n",
      "  \"Item\": \"lamp\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n",
      "\n",
      "2.2 综合情感推断和信息提取\n",
      "\n",
      "```python prompt = f\"\"\" Identify the following items from the review text: - Sentiment (positive or negative) - Is the reviewer expressing anger? (true or false) - Item purchased by reviewer - Company that made the item\n",
      "\n",
      "The review is delimited with triple backticks. \\ Format your response as a JSON object with \\ \"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys. If the information isn't present, use \"unknown\" \\ as the value. Make your response as short as possible. Format the Anger value as a boolean.\n",
      "\n",
      "Review text: {lamp_review} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "{\n",
      "  \"Sentiment\": \"positive\",\n",
      "  \"Anger\": false,\n",
      "  \"Item\": \"lamp\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n",
      "\n",
      "3.1 推断讨论主题\n",
      "\n",
      "```python story = \"\"\" In a recent survey conducted by the government, public sector employees were asked to rate their level of satisfaction with the department they work at. The results revealed that NASA was the most popular department with a satisfaction rating of 95%.\n",
      "\n",
      "One NASA employee, John Smith, commented on the findings, stating, \"I'm not surprised that NASA came out on top. It's a great place to work with amazing people and incredible opportunities. I'm proud to be a part of such an innovative organization.\"\n",
      "\n",
      "The results were also welcomed by NASA's management team, with Director Tom Johnson stating, \"We are thrilled to hear that our employees are satisfied with their work at NASA. We have a talented and dedicated team who work tirelessly to achieve our goals, and it's fantastic to see that their hard work is paying off.\"\n",
      "\n",
      "The survey also revealed that the Social Security Administration had the lowest satisfaction rating, with only 45% of employees indicating they were satisfied with their job. The government has pledged to address the concerns raised by employees in the survey and work towards improving job satisfaction across all departments. \"\"\" ```\n",
      "\n",
      "```python prompt = f\"\"\" Determine five topics that are being discussed in the \\ following text, which is delimited by triple backticks.\n",
      "\n",
      "Make each item one or two words long.\n",
      "\n",
      "Format your response as a list of items separated by commas. Give me a list which can be read in Python.\n",
      "\n",
      "Text sample: {story} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "survey, satisfaction rating, NASA, Social Security Administration, job satisfaction\n",
      "\n",
      "python response.split(sep=',')\n",
      "\n",
      "['survey',\n",
      " ' satisfaction rating',\n",
      " ' NASA',\n",
      " ' Social Security Administration',\n",
      " ' job satisfaction']\n",
      "\n",
      "3.2 为特定主题制作新闻提醒\n",
      "\n",
      "python topic_list = [ \"nasa\", \"local government\", \"engineering\", \"employee satisfaction\", \"federal government\" ]\n",
      "\n",
      "```python prompt = f\"\"\" Determine whether each item in the following list of \\ topics is a topic in the text below, which is delimited with triple backticks.\n",
      "\n",
      "Give your answer as list with 0 or 1 for each topic.\\\n",
      "\n",
      "List of topics: {\", \".join(topic_list)}\n",
      "\n",
      "Text sample: {story} \"\"\" response = get_completion(prompt) print(response) ```\n",
      "\n",
      "[1, 0, 0, 1, 1]\n",
      "\n",
      "python topic_dict = {topic_list[i] : eval(response)[i] for i in range(len(eval(response)))} print(topic_dict) if topic_dict['nasa'] == 1: print(\"ALERT: New NASA story!\")\n",
      "\n",
      "{'nasa': 1, 'local government': 0, 'engineering': 0, 'employee satisfaction': 1, 'federal government': 1}\n",
      "ALERT: New NASA story!\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:20:14.309027Z",
     "start_time": "2025-06-16T07:20:14.279068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 切分文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "split_docs = text_splitter.split_documents(texts)"
   ],
   "id": "f67b6b139a1321fe",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.4.2 构建Chroma向量库\n",
    "\n",
    "Langchain 集成了超过 30 个不同的向量存储库。我们选择 Chroma 是因为它轻量级且数据存储在内存中，这使得它非常容易启动和开始使用。\n",
    "\n",
    "LangChain 可以直接使用 OpenAI 和百度千帆的 Embedding，同时，我们也可以针对其不支持的 Embedding API 进行自定义，例如，我们可以基于 LangChain 提供的接口，封装一个 zhipuai_embedding，来将智谱的 Embedding API 接入到 LangChain 中。在本章的[附LangChain自定义Embedding封装讲解](./附LangChain自定义Embedding封装讲解.ipynb)中，我们以智谱 Embedding API 为例，介绍了如何将其他 Embedding API 封装到 LangChain\n",
    "中，欢迎感兴趣的读者阅读。\n",
    "\n",
    "**注：如果你使用智谱 API，你可以参考讲解内容实现封装代码，也可以直接使用我们已经封装好的代码[zhipuai_embedding.py](./zhipuai_embedding.py)，将该代码同样下载到本 Notebook 的同级目录，就可以直接导入我们封装的函数。在下面的代码 Cell 中，我们默认使用了智谱的 Embedding，将其他两种 Embedding 使用代码以注释的方法呈现，如果你使用的是百度 API 或者 OpenAI API，可以根据情况来使用下方 Cell 中的代码。**"
   ],
   "id": "7f89fd021b17dcfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:33:43.251308Z",
     "start_time": "2025-06-16T11:33:43.200038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "#定义embeddings\n",
    "embeddings = ZhipuAIEmbeddings()\n",
    "\n",
    "#定义持久化路径\n",
    "persist_directory = '../data_base/vector_db/chroma'"
   ],
   "id": "4ab3e157ddf57152",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:31:15.777210Z",
     "start_time": "2025-06-16T11:31:15.647889Z"
    }
   },
   "cell_type": "code",
   "source": "!rm -rf '../data_base/vector_db/chroma'",
   "id": "ea95456718cb7641",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:36:05.014701Z",
     "start_time": "2025-06-16T11:35:34.166411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory#允许我们将persist_directory目录保存到磁盘上\n",
    ")"
   ],
   "id": "3b584c7d9c99c250",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:37:52.758225Z",
     "start_time": "2025-06-16T11:37:52.752676Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")",
   "id": "7974c6febef142c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：1004\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.4.3 向量检索\n",
    "\n",
    "Chroma的相似度搜索使用的是余弦距离，即：\n",
    "$$\n",
    "similarity = cos(A, B) = \\frac{A \\cdot B}{\\parallel A \\parallel \\parallel B \\parallel} = \\frac{\\sum_1^n a_i b_i}{\\sqrt{\\sum_1^n a_i^2}\\sqrt{\\sum_1^n b_i^2}}\n",
    "$$\n",
    "其中$a_i$、$b_i$分别是向量$A$、$B$的分量。\n",
    "\n",
    "当你需要数据库返回严谨的按余弦相似度排序的结果时可以使用`similarity_search`函数。"
   ],
   "id": "63c20053a7dd71ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:40:36.376565Z",
     "start_time": "2025-06-16T11:40:35.919420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question=\"什么是大语言模型\"\n",
    "\n",
    "sim_docs = vectordb.similarity_search(question,k=3)\n",
    "print(f\"检索到的内容数：{len(sim_docs)}\")"
   ],
   "id": "ccebc0b75bb2ecdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：3\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:41:46.885385Z",
     "start_time": "2025-06-16T11:41:46.881859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n{sim_doc.page_content[:500]}\", end=\"\\n--------------\\n\")"
   ],
   "id": "d43e774e47d0b8ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容: \n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 DeepLearning.AI 的姊妹公司 AI Fund 的团队一直在与许多初创公司合作，将这些技术应用于诸多应用程序上。很兴奋能看到 LLM API 能够让开发人员非常快速地构建应用程序。\n",
      "\n",
      "在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。\n",
      "--------------\n",
      "检索到的第1个内容: \n",
      "第六章 文本转换\n",
      "\n",
      "大语言模型具有强大的文本转换能力，可以实现多语言翻译、拼写纠正、语法调整、格式转换等不同类型的文本转换任务。利用语言模型进行各类转换是它的典型应用之一。\n",
      "\n",
      "在本章中,我们将介绍如何通过编程调用API接口，使用语言模型实现文本转换功能。通过代码示例，读者可以学习将输入文本转换成所需输出格式的具体方法。\n",
      "\n",
      "掌握调用大语言模型接口进行文本转换的技能，是开发各种语言类应用的重要一步。文本转换功能的应用场景也非常广泛。相信读者可以在本章的基础上，利用大语言模型轻松开发出转换功能强大的程序。\n",
      "\n",
      "一、文本翻译\n",
      "\n",
      "文本翻译是大语言模型的典型应用场景之一。相比于传统统计机器翻译系统，大语言模型翻译更加流畅自然，还原度更高。通过在大规模高质量平行语料上进行 Fine-Tune，大语言模型可以深入学习不同语言间的词汇、语法、语义等层面的对应关系，模拟双语者的转换思维，进行意义传递的精准转换，而非简单的逐词替换。\n",
      "--------------\n",
      "检索到的第2个内容: \n",
      "与基础语言模型不同，指令微调 LLM 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行预训练，掌握语言的基本规律。在此基础上进行进一步的训练与微调（finetune），输入是指令，输出是对这些指令的正确回复。有时还会采用RLHF（reinforcement learning from human feedback，人类反馈强化学习）技术，根据人类对模型输出的反馈进一步增强模型遵循指令的能力。通过这种受控的训练过程。指令微调 LLM 可以生成对指令高度敏感、更安全可靠的输出，较少无关和损害性内容。因此。许多实际应用已经转向使用这类大语言模型。\n",
      "--------------\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "如果只考虑检索出内容的相关性会导致内容过于单一，可能丢失重要信息。\n",
    "\n",
    "最大边际相关性 (`MMR, Maximum marginal relevance`) 可以帮助我们在保持相关性的同时，增加内容的丰富度。\n",
    "\n",
    "核心思想是在已经选择了一个相关性高的文档之后，再选择一个与已选文档相关性较低但是信息丰富的文档。这样可以在保持相关性的同时，增加内容的多样性，避免过于单一的结果。"
   ],
   "id": "196bab70a90f586e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:48:00.287615Z",
     "start_time": "2025-06-16T11:47:59.844660Z"
    }
   },
   "cell_type": "code",
   "source": "mmr_docs = vectordb.max_marginal_relevance_search(question,k=3)",
   "id": "2aa1e50802d76d6d",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:48:19.137625Z",
     "start_time": "2025-06-16T11:48:19.135174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, sim_doc in enumerate(mmr_docs):\n",
    "    print(f\"MMR 检索到的第{i}个内容: \\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ],
   "id": "3c5a9d6376be73cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR 检索到的第0个内容: \n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 Deep\n",
      "--------------\n",
      "MMR 检索到的第1个内容: \n",
      "学生计算的总费用：450x+10万美元\n",
      "实际计算的总费用：360x+10万美元\n",
      "学生计算的费用和实际计算的费用是否相同：否\n",
      "学生的解决方案和实际解决方案是否相同：否\n",
      "学生的成绩：不正确\n",
      "\n",
      "三、局限性\n",
      "\n",
      "开发大模型相关应用时请务必铭记：\n",
      "\n",
      "虚假知识：模型偶尔会生成一些看似真实实则编造的知识\n",
      "\n",
      "在开发与应用语言模型时，需要注意它们可能生成虚假信息的风险。尽管模型经过大规模预训练，掌握了丰富知识，但它实\n",
      "--------------\n",
      "MMR 检索到的第2个内容: \n",
      "行推导。\n",
      "对于任意样本, 在不考虑样本本身之前(即先验), 若瞎猜一下它由第i 个高斯混合成分生成的概率\n",
      "P (zj = i), 那么肯定按先验概率α1, α2, . . . , αk 进行猜测, 即P (zj = i) = αi 。若考虑样本本身带来的信\n",
      "息(即后验), 此时再猜一下它由第i 个高斯混合成分生成的概率pM (zj = i | xj), 根据贝叶斯公式, 后验概\n",
      "率pM (zj =\n",
      "--------------\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
